# Introducción

La inteligencia artificial como un pensamiento de lo que hoy denominaríamos ciencia ficción tiene por detrás más recorrido que el trayecto exacto y duro que hoy tenemos desarrollado. Es un campo donde claramente se observa que tanto el pensamiento como el arte precede a lo concreto, y donde filósofos han destinado gran parte de sus tiempos tratando de resolver cuestiones relacionadas a ella.

# Inteligencia artificial débil

Los filósofos llaman inteligencia artificial debil a la afirmación de que las máquinas solo pueden actuar como si fueran inteligentes, a diferencia de la IA fuerte que defiende que las máquinas realmente pueden pensar (y no estar simulando un pensamiento), una idea desarrollada en la próxima sección.

En la conferencia donde se definió el campo de la inteligencia artificial hubo afirmaciones tanto de partidarios como de detractores de la IA débil. Ante esto, una pregunta reiterada pero siempre válida es ¿pueden las máquinas pensar? y la respuesta varía según cómo se defina la IA. Es de interés, pues, tener en mente comparar la IA con un humano.

Edsger Dijkstra (1984) dijo “La pregunta de si las máquinas pueden pensar... es tan relevante como la pregunta de si los submarinos pueden nadar". En efecto, las capacidades de un submarino están dadas por la pregunta, más no por una respuesta literal a si es capaz de hacerlo (ya que esta puede estar definida en función de aletas, cola, o brazos).

Alan Turing, en "Computing Machinery and Intelligence" (1950), sugiere que en vez de preguntarnos si las máquinas pueden pensar, deberíamos preguntarnos si las máquinas pueden pasar un test de inteligencia (el llamado Test de Turing).

Con algunos éxitos relativos 60 años después, aún son válidas algunas objeciones planteadas por el mismo Turing.

### El argumento de la incapacidad

Este argumento afirma que "una máquina nunca puede hacer X". Turing lista lo siguiente:

> Be kind, resourceful, beautiful, friendly, have initiative,
> have a sense of humor, tell right from wrong, make mistakes,
> fall in love, enjoy strawberries and cream, make someone
> fall in love with it, learn from experience, use words
> properly, be the subject of its own thought, have as much
> diversity of behavior as man, do something really new.

Sin embargo, los ordenadores pueden realizar muchas de estas tareas igual o mejor que los humanos. Por detallar algunas, el experto en ajedrez por ordenador David Levy predijo que en 2050 las personas se enamorarán de robots humanoides. Pueden jugar ajedrez, y otros juegos. Además, contribuyeron al estudio en diversas áreas como la química, astronomía, biología, etc. Ya por 1955, Paul Meehl encontró que sencillos algoritmos de aprendizaje estadístico (como la regresión lineal y el teorema de Bayes) predicen mejor que expertos entrenados en el área.

Aunque, vale aclarar que si bien pueden realizar todas estas tareas, no implica que tengan un entendimiento de lo que estén realizando.

### La objeción matemática

J. R. Lucas declaró que el Teorema de la Incompletitud de Godel demuestra que las máquinas son mentalmente inferiores a los humanos, debido a que éstas, como sistemas formales, están limitadas por el teorema mientras que los humanos no.

Sin embargo, hay algunos problemas detras de la afirmación:

1. Las computadoras, a pesar de ser máquinas de Turing, no comparte la característica de ser infinita. Entonces, es posible describir cualquier computadora como un largo sistema en lógica proposicional (por ende, no está sujeta al teorema de incompletitud).

2. Una computadora puede asegurar la siguiente frase mientras que J. R. Lucas no podría por caer en una contradicción: "J. R. Lucas no puede asegurar consistentemente que esta frase es cierta". Del mismo modo, conocemos las extraordinarias capacidades para resolver problemas matemáticos de una computadora, pero ello no quiere decir que por no contar con las mismas capacidades un humano está limitado en su habilidad de pensar.

3. A pesar de que es posible demostrar que los ordenadores pueden tener limitaciones, no es posible hacer lo mismo con los humanos. De hecho, es imposible demostrar que los humanos no están sujetos al teorema de incompletitud de Gödel, porque cualquier prueba rigurosa requeriría una formalización del supuesto talento humano no formalizable, y por tanto se refutaría a sí misma.

### El argumento de informalidad

Sugiere que el comportamiento humano es demasiado complejo como para ser capturado por un conjunto simple de reglas que pueda replicar una computadora. La inhabilidad de capturar todo en un conjunto de reglas lógicas es llamado el problema de la cuantificación en IA.

Uno de sus exponentes, Hubert Dreyfus asegura que la experiencia humana incluye el conocimiento de algunas reglas en un contexto holístico dentro del cual los humanos operan. Aparentemente cada humano tiene "un sentido directo de cómo se hacen las cosas y qué podemos esperar de ellas". Sin embargo, esto no quiere decir que no exista un proceso de pensamiento detrás de este sentido directo.

# Inteligencia artificial fuerte

¿Las máquinas realmente pueden pensar?

La objeción fue anticipada por el mismo Turing, citando al profesor Geoffrey Jefferson:

> Hasta que una máquina no pudiera escribir un soneto
> o componer un concierto a causa de los pensamientos
> y las emociones sentidas, y no por la caída fortuita
> de símbolos, no podríamos convenir en que la máquina
> equivale al cerebro, es decir, no sólo escribirlo
> sino saber que lo ha escrito.

Este argumento es llamado por Turing como el argumento de la conciencia: una computadora debe ser consciente de sus propios estados mentales y acciones.

No obstante, Turing sostiene que la pregunta está mal definida puesto que cada humano solo puede tener conciencia de sí mismo, pero es carente de los estados mentales de los demás. Dice Turing: "En lugar de discutir continuamente sobre este punto, es habitual tener la cortés convención de que todos piensan". Sugiriendo que Jefferson extendería esta cortesía a las máquinas si tuviera una experiencia inteligente con ellas y concluyendo que a medida que las máquinas alcancen altos niveles de sofisticación, la cuestion acabará desapareciendo por sí sola y con ella arrastraría las diferencias planteadas entre IA débil y fuerte.

En contra de esto, aún se puede insistir en que los humanos tienen mentes reales y las máquinas podrían o no tenerlas. Este problema debe ser abordado teniendo en cuenta que los humanos tambien tienen cuerpo y cómo éste se relaciona con la mente, ya que desde este punto podríamos dar luz a la cuestión de sí las máquinas pueden tener mentes reales. Hay que tener presente, desde luego, la teoría dualista de René Descartes que sostiene que cuerpo y mente están separados y la teoría del fisicalismo que asegura que los estados mentales son estados físicos - abriendo la puerta a la posibilidad de una IA fuerte.


### Estados mentales y el cerebro en un frasco

Intentando explicar qué significa que una persona se halle en un cierto estado mental concreto, los filósofos fisicalistas se han centrado particularmente en los estados intencionales: aquellos consisten en creer, saber, desear, tener, etc., que se refieren a algún aspecto del mundo exterior. Por ejemplo,

### Funcionalismo y el experimento de sustitución de cerebro

La teoría del funcionalismo dice que un estado mental es cualquier condición causal intermedia entre la entrada y la salida. Según esta teoría, dos sistemas cualesquiera con procesos causales isomórficos tendrían los mismos estados mentales. Esto quiere decir que un ordenador podría tener los mismos estados mentales de una persona. Una forma de ver claramente esto es a través del experimento de sustitución del cerebro, donde -en resumidas palabras- afirma que un sujeto no perdería su conciencia y no sería perceptible por terceros a medida que sus neuronas son reemplazadas por otras artificiales.

Sus detractores argumentan, sin embargo, que la pérdida total de la conciencia es inevitable, pero la pregunta es si esta es instantánea o no. Es poco probable que sea instantánea teniendo en cuenta que sería rápidamente observable por terceros. Pero si esta es gradual, el sujeto puede expresar acciones que pueden dar a conocer lo que le está sucediendo. Además, una vez concretada la pérdida total, ¿cómo la veríamos reflejada? ¿cómo serían sus instintos?

Pueden ocurrir tres cosas:

1. Los mecanismos causales de la conciencia pueden seguir operando en cerebros electrónicos, por lo tanto es conciente.

2. Los eventos mentales conscientes en el cerebro normal no tienen conexión causal con el comportamiento y están ausentes en el cerebro artificial, por lo tanto no es conciente.

3. El experimento es imposible, invalidando cualquier especulación sobre él.

Patricia Churchland señala que los argumentos funcionalistas que operan a nivel neurona tambien pueden ser escalables, por lo que reemplazar todo el cerebro por un circuito que se actualiza y mapea desde entradas hasta las salidas a través de una enorme tabla de búsqueda, aún mantendría la conciencia.

### Naturalismo biológico y el cuarto chino

El naturalismo biológico de John Searle señala que los estados mentales son características mentales de alto nivel que son causadas por procesos físicos de bajo nivel en las neuronas, y lo que importa son las propiedades (no especificadas) de las neuronas. Así, los estados mentales únicamente podrían ser duplicados sobre un programa con la misma arquitectura con igual poder causal de las neuronas.

Para apoyar su punto de vista, Searle describe un sistema hipotético que claramente está ejecutando un programa y pasa el test de Turing, pero que igualmente claramente (según Searle) no entiende nada de sus entradas y salidas. Su conclusión es que ejecutar el programa adecuado (tener los resultados correctos) no es condición suficiente para ser una mente.

Agrega que algunas máquinas sí tienen mente: los humanos son máquinas biológicas con mente. Según Searle, los cerebros humanos pueden o no ejecutar algo parecido a un programa de IA, pero si lo hacen, esa no es la razón por la que son mentes. Se necesita algo más para hacer una mente, según Searle, algo equivalente a los poderes causales de las neuronas individuales. No se especifica cuáles son estos poderes. No obstante, las neuronas están desde mucho antes de que se desarrollara la conciencia; luego, ¿qué impide que otro órgano no pueda ser una mente?

### Conciencia y la brecha explicativa

¿Por qué se siente algo al tener ciertos estados cerebrales mientras que presumiblemente no se siente nada al tener otros estados físicos (por ejemplo, ser un objeto inanimado)? Considerando el experimento del espectro invertido junto a la experiencia subjetiva, filósofos concluyen que los seres humanos son sencillamente incapaces de formarse una comprensión adecuada de su propia conciencia.

# Ética y riesgos de desarrollar inteligencia artificial

Todo avance científico y tecnológico acarreo a sus espaldas consecuencias no deseables para muchas personas. Centrarse ya no en poder desarrollar IA, sino en si deberíamos también es un debate importante puesto que nos corresponde como profesionales reorientar éticamente los desarrollos e investigaciones. Desafortunadamente, a diferencia de cualquier avance visto anteriormente, la IA puede acarrear problemas más preocupantes:

1. Las personas pueden perder su trabajo: muchos sistemas informáticos dependen en gran medida de algoritmos de IA, por lo que miles de trabajadores ya están siendo desplazados de sus puestos y se espera que en un futuro esto incremente mucho más. Sin embargo, también está creando puestos de trabajo que requieren una preparación más sofisticada, aumentado a su vez el nivel de ingresos de un trabajador.

2. Pueden tener demasiado (o muy poco) tiempo libre: Alvin Toffler aseguró que la semana laboral fue reducia en un 50 por ciento desde el inicio del siglo XX, prediciendo que sucedería lo mismo a mediados de los 2000. Por otro lado, trabajadores cualificados que mantienen sistemas computarizados que funcionan la 24 horas del día están forzados a cumplir largas horas de trabajo.

3. La gente podría perder su sentido de ser única: Weizembaum argumenta que la investigación de IA puede hacer realidad la idea de que los humanos son autómatas, desencadenando la idea de la no autonomía de la humanidad. Esto no suena descabellado, ya que lo discutido en la sección de IA fuerte puede avalar las afirmaciones de Weizembaum.

4. Los sistemas IA pueden utilizarse para fines no deseados: Los sistemas autónomos de IA son un común en conflictos militares, desde sistemas de vuelo y vehículos en tierra. A esto le sumamos que el proceso de toma de decisiones de una IA puede fallar, ocasionando el asesinato de civiles inocentes. Del mismo modo, tecnologías de reconocimiento ocasiona la pérdida de libertades y privacidad de la población.

5. El uso de los sistemas de IA podría dar lugar a una pérdida de responsabilidad: puede darse principalmente a la hora del diagnóstico médico. Si un sistema experto brinda su opinión en base a sus estudios, ¿quién será responsable si este diagnóstico es erróneo?

6. El éxito de la IA podría significar el fin de la raza humana: sistemas de IA poseen mayores riesgos que el software tradicional. Por ejemplo, los misiles de defensa pueden interpretar erróneamente un ataque y lanzar un contraataque, cargando con las consecuencias de ello. Puede darse la situación de tener una máquina ultrainteligente (una máquina que puede sobrepasar todas las actividades intelectuales de un hombre) perdiendo los humanos la capacidad de comprenderlas y, según ciertos teóricos, abrir las puertas al transhumanismo.

# Conclusión
